# #################################
# Training a whisper.0 + MLP classifier system for Arabic Dialect Identification (ADI).
#
# Authors:
#  * Haroun Elleuch
# #################################

# Seed needs to be set at top of yaml, before objects with parameters are made
seed: 1986
__set_seed: !apply:speechbrain.utils.seed_everything [!ref <seed>]

# Set up folders for reading from and writing to
output_folder: !ref results/whisper-base/adi_17_full/<seed>
save_folder: !ref <output_folder>/save
manifest_folder: ../../dataset/manifest
train_log: !ref <output_folder>/train_log.txt
train_csv: !ref <manifest_folder>/adi17_segmented.csv
dev_csv: !ref <manifest_folder>/adi17_dev.csv
test_csv: !ref <manifest_folder>/adi17_test.csv
fewer_eval_classes: false

ckpt_interval_minutes: 10 # save checkpoint every N min

# skip_prep:  # TODO: integrate data prep pipeline in train script

# The train logger writes training statistics to a file, as well as stdout.
train_logger: !new:speechbrain.utils.train_logger.FileTrainLogger
  save_file: !ref <train_log>

metrics_log_dir: !ref <output_folder>/metrics/

error_stats: !name:speechbrain.utils.metric_stats.MetricStats
  metric: !name:speechbrain.nnet.losses.classification_error
    reduction: batch

####################### Training Parameters ####################################
number_of_epochs: 40
train_batch_size: 16
eval_batch_size: 4

n_languages: 17
features_dim: 512
# tiny => 384
# base => 512
# small => 768
# medium => 1024
# large => 1280

whisper_hub: openai/whisper-base
whisper_folder: !ref <whisper_hub>

# Learning rates
lr: 0.0001
lr_whisper: 0.00001

pooling: attention # Should be one of "attention", "avg", or "max"

# Dataloaders
num_workers: 4
drop_last: True
train_dataloader_options:
  num_workers: !ref <num_workers>
  batch_size: !ref <train_batch_size>
  drop_last: !ref <drop_last>
  shuffle: True

test_dataloader_options:
  num_workers: !ref <num_workers>
  batch_size: !ref <eval_batch_size>
  shuffle: True

############################## Models ##########################################
#Whisper model
whisper: !new:speechbrain.lobes.models.huggingface_transformers.whisper.Whisper
  source: !ref <whisper_hub>
  encoder_only: True
  freeze_encoder: False
  save_path: !ref <whisper_folder>

# Attention Pooling layer (Only used if pooling param is set to attention)
attention_pooling: !new:speechbrain.nnet.pooling.AttentionPooling
  input_dim: !ref <features_dim>

output_mlp: !new:speechbrain.nnet.linear.Linear
  input_size: !ref <features_dim>
  n_neurons: !ref <n_languages>
  bias: False

# The first object passed to the Brain class is this "Epoch Counter"
# which is saved by the Checkpointer so that training can be resumed
# if it gets interrupted at any point.
epoch_counter: !new:speechbrain.utils.epoch_loop.EpochCounter
  limit: !ref <number_of_epochs>

# Objects in "modules" dict will have their parameters moved to the correct
# device, as well as having train()/eval() called on them by the Brain class.
modules:
  whisper: !ref <whisper>
  attention_pooling: !ref <attention_pooling>
  output_mlp: !ref <output_mlp>

model: !new:torch.nn.ModuleList
  - [!ref <attention_pooling>, !ref <output_mlp>]

log_softmax: !new:speechbrain.nnet.activations.Softmax
  apply_log: True

compute_cost: !name:speechbrain.nnet.losses.nll_loss
  # This optimizer will be constructed by the Brain class after all parameters
  # are moved to the correct device. Then it will be added to the checkpointer.


opt_class: !name:torch.optim.Adam
  lr: !ref <lr>
  weight_decay: 0.000002

whisper_opt_class: !name:torch.optim.Adam
  lr: !ref <lr_whisper>

lr_annealing: !new:speechbrain.nnet.schedulers.NewBobScheduler
  initial_value: !ref <lr>
  improvement_threshold: 0.0025
  annealing_factor: 0.9
  patient: 0

lr_annealing_whisper: !new:speechbrain.nnet.schedulers.NewBobScheduler
  initial_value: !ref <lr_whisper>
  improvement_threshold: 0.0025
  annealing_factor: 0.9

############################## Logging and Pretrainer ##########################

# This object is used for saving the state of training both so that it
# can be resumed if it gets interrupted, and also so that the best checkpoint
# can be later loaded for evaluation or inference.
checkpointer: !new:speechbrain.utils.checkpoints.Checkpointer
  checkpoints_dir: !ref <save_folder>
  recoverables:
    whisper: !ref <whisper>
    attention_pooling: !ref <attention_pooling>
    output_mlp: !ref <output_mlp>
    counter: !ref <epoch_counter>
